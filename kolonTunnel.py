import camelot
import streamlit as st
import pdfplumber
import pandas as pd
import time
from kolonAgGrid import create_st_aggrid
from kolonKeywords import find_similar_keywords
import re
import math
import numpy as np
import os

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")
start_time = time.time()  # ì‹œì‘ ì‹œê°„ ì¸¡ì •

with st.sidebar:
    option = st.radio("#### :orange[PDF í…Œì´ë¸” ì¶”ì¶œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ]", ["Camelot (ê²©ì ê¸°ë°˜)", "pdfplumber (í…ìŠ¤íŠ¸ ê¸°ë°˜)"], index=0)
    # êµ¬ë¶„ì—´ = st.number_input("êµ¬ë¶„ì—´", min_value=1, max_value=100, value=1, step=1)

    # PDF íŒŒì¼ ì—…ë¡œë“œ UI
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

    # í˜„ì¬ í´ë”ì—ì„œ PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    pdf_files = [f for f in os.listdir() if f.endswith(".pdf")]

    # ì‚¬ìš©ìì—ê²Œ ë‹¤ìš´ë¡œë“œí•  PDF ì„ íƒ
    selected_pdf = st.selectbox("ë‹¤ìš´ë¡œë“œí•  PDF íŒŒì¼ ì„ íƒ", pdf_files, index=1)

    # ì„ íƒí•œ PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if selected_pdf:
        with open(selected_pdf, "rb") as file:
            btn = st.download_button(label="PDF ë‹¤ìš´ë¡œë“œ", data=file, file_name=selected_pdf, mime="application/pdf")


# íŒŒì¼ ì„ íƒ
if uploaded_file is not None:
    file_path = uploaded_file.name  # ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼
    with open(file_path, "wb") as f:
        f.write(uploaded_file.read())  # íŒŒì¼ ì €ì¥
else:
    file_path = "a1.pdf"  # ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©


@st.cache_data
def extract_tables_camelot(file_path):
    return camelot.read_pdf(file_path, pages="all", flavor="lattice")


@st.cache_data
def extract_tables_pdfplumber(file_path):
    with pdfplumber.open(file_path) as pdf:
        extracted_tables = []
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if table:
                    df = pd.DataFrame(table)
                    extracted_tables.append(df)
    return extracted_tables


# ì„ íƒëœ ì˜µì…˜ì— ë”°ë¼ í‘œ ì¶”ì¶œ
if "camelot" in option:
    extracted_tables = extract_tables_camelot(file_path)
else:
    extracted_tables = extract_tables_pdfplumber(file_path)
# extracted_tables


def clean_text(text):
    # None ë˜ëŠ” NaN ê°’ ì²˜ë¦¬
    if text is None or (isinstance(text, float) and math.isnan(text)):
        return ""
    if not isinstance(text, str):  # ë¬¸ìì—´ì´ ì•„ë‹ ê²½ìš°, ì¼ë‹¨ ë¬¸ìì—´ë¡œ ë³€í™˜í–ˆìŒ
        text = str(text)
    # ê°œí–‰ë¬¸ì, íƒ­ ë“± ì œê±° í›„ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
    text = text.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
    # ë‹¤ì¤‘ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì¶•ì†Œ
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()  # ì•ë’¤ ê³µë°± ì œê±°
    return text


# extracted_tablesê°€ DataFrameë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¼ê³  ê°€ì •
cleaned_tables = []
for df in extracted_tables:
    # dfì˜ ëª¨ë“  ì…€ì— ëŒ€í•´ clean_text í•¨ìˆ˜ ì ìš©
    cleaned_df = df.map(clean_text)
    cleaned_tables.append(cleaned_df)

# íƒ­ ìƒì„±
tabs = st.tabs(["Result"] + [f"í‘œ {i+1}" for i in range(len(cleaned_tables))])
for i, tab in enumerate(tabs[1:]):
    with tab:
        df_table = cleaned_tables[i]
        if df_table.empty:
            st.warning("ğŸ“Œ PDFì—ì„œ ë°ì´í„°ê°€ í¬í•¨ëœ í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df_table.columns = list(range(len(df_table.columns)))
            df_table = df_table.map(lambda x: "" if x is None else x)
            st.dataframe(df_table, height=1200, use_container_width=True)

with tabs[0]:
    # df = {
    #     "êµ´ì°©ê³µë²•": ["A", "A", "B", "B", "C", "C", "D", "D", "E", "E"],
    #     "ì²œê³µì¥": ["í„°ë„", "í„°ë„ ë‹¨ë©´êµ°", 300, 400, 500, 600, 700, 800, 900, 1000],
    #     "êµ´ì§„ì¥": [100, 200, "í„°ë„ ë‹¨ë©´", 400, 500, 600, 700, 800, 900, 1000],
    #     "ì‹œì ë°©í–¥": [100, 200, "í„°ë„", 400, 500, 600, 700, 800, 900, 1000],
    #     "ì¢…ì ë°©í–¥": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
    #     "êµ´ì°©ëŸ‰": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
    #     "ì—¬êµ´ëŸ‰": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
    #     "ìˆí¬ë¦¬íŠ¸": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
    # }
    df_output = pd.DataFrame()
    # ì²« ë²ˆì§¸ ìœ„ì¹˜(ì¸ë±ìŠ¤ 0)ì— ì—´ ì‚½ì…
    v = cleaned_tables[0]
    df_output.insert(0, 'ì´ë¦„', v.iloc[4:, 1])
    df_output.insert(0, 'ë‹¨ë©´', v.iloc[4:, 2])
    df_output.insert(0, 'ìƒí•˜ë¶€', v.iloc[4:, 3])


keyword_results = {}
for page_idx, df in enumerate(cleaned_tables):
    keyword_dict = {
        "í„°ë„ ë‹¨ë©´êµ°": ["í„°ë„ë‹¨ë©´êµ°", "í„°ë„ë‹¨ë©´", "í„°ë„ ë‹¨ë©´", "í„°ë„ ë‹¨ë©´êµ°"],
        "êµ´ì°© ê³µë²•": ["êµ´ì°©ê³µë²•", "êµ´ì°© ê³µë²•"],
        "êµ´ì§„ì¥": ["êµ´ì§„ì¥", "êµ´ì§„ ê±°ë¦¬", "êµ´ì§„"],
        "ì²œê³µì¥": ["ì²œê³µì¥", "ì²œê³µ ê±°ë¦¬", "ì²œê³µ"],
        "ì‹œì ": ["ì‹œì ë°©í–¥", "ì‹œì ", "ì‹œì  ë°©í–¥", "ì—°ì¥", "ëŒ€ë©´í„°ë„"],
        "ì¢…ì ": ["ì¢…ì ë°©í–¥", "ì¢…ì ", "ì¢…ì  ë°©í–¥"],
        "më‹¹ í‰ê· ë‹¨ìœ„ìˆ˜ëŸ‰": ["më‹¹", "më‹¹ í‰ê· ë‹¨ìœ„ìˆ˜ëŸ‰"],
        "më‹¹ êµ´ì°©ëŸ‰": ["êµ´ì°©ëŸ‰", "êµ´ì°© ëŸ‰"],
        "më‹¹ ì—¬êµ´ëŸ‰": ["ì—¬êµ´ëŸ‰", "ì—¬êµ´ ëŸ‰"],
        "më‹¹ ìˆí¬ë¦¬íŠ¸": ["ìˆí¬ë¦¬íŠ¸", "ìˆí¬ë¦¬íŠ¸ ëŸ‰", "ìˆí¬ë¦¬íŠ¸ ìˆ˜ëŸ‰", 'më‹¹ ìˆí¬ë¦¬íŠ¸'],
        "më‹¹ ìˆí¬ë¦¬íŠ¸ ë¦¬ë°”ìš´ë“œ": ["ìˆí¬ë¦¬íŠ¸ ë¦¬ë°”ìš´ë“œ", "ìˆí¬ë¦¬íŠ¸ ë¦¬ë°”ìš´ë“œìˆ˜ ëŸ‰", "ìˆí¬ë¦¬íŠ¸ ë¦¬ë°”ìš´ë“œ ìˆ˜ëŸ‰"],
        "1ë°œíŒŒ ì²œê³µìˆ˜": ["1ë°œíŒŒ ì²œê³µìˆ˜", "1ë°œíŒŒ ì²œê³µ ìˆ˜", "1ë°œíŒŒ ì²œê³µ ìˆ˜ëŸ‰", "1ë°œíŒŒ ì²œê³µìˆ˜(ë¬´ì¥ì•½ê³µí¬í•¨)"],
        "Dynamite <32mm>": ["Dynamite <32mm>", "Dynamite 32mm", "Dynamite 32mm ëŸ‰"],
        "Emulsion <32mm>": ["Emulsion <32mm>", "Emulsion 32mm", "Emulsion 32mm ëŸ‰"],
        "Emulsion <25mm>": ["Emulsion <25mm>", "Emulsion 25mm", "Emulsion 25mm ëŸ‰"],
        "ì •ë°€ í­ì•½": ["ì •ë°€ í­ì•½", "ì •ë°€ í­ì•½ ëŸ‰", "ì •ë°€ í­ì•½ ìˆ˜ëŸ‰"],
        "ë‡Œê´€ <MS>": ["ë‡Œê´€ <MS>", "ë‡Œê´€ MS", "ë‡Œê´€ MS ëŸ‰"],
        "ë‡Œê´€ <LP>": ["ë‡Œê´€ <LP>", "ë‡Œê´€ LP", "ë‡Œê´€ LP ëŸ‰"],
        "ì—°ê²°ë‡Œê´€ <Starter>": ["ì—°ê²°ë‡Œê´€ <Starter>", "ì—°ê²°ë‡Œê´€ Starter", "ì—°ê²°ë‡Œê´€ Starter ëŸ‰"],
        "ì—°ê²°ë‡Œê´€ <Bunch>": ["ì—°ê²°ë‡Œê´€ <Bunch>", "ì—°ê²°ë‡Œê´€ Bunch", "ì—°ê²°ë‡Œê´€ Bunch ëŸ‰"],
        "ê²©ì ì§€ë³´": ["ê²©ì ì§€ë³´", "ê²©ì ì§€ë³´ ëŸ‰", "ê²©ì ì§€ë³´ ìˆ˜ëŸ‰"],
        "ë¡ë³¼íŠ¸ ê·œê²©": ["ë¡ë³¼íŠ¸ ê·œê²©", "ê·œê²©"],
        "ë¡ë³¼íŠ¸ ì„¤ì¹˜ìˆ˜": ["ë¡ë³¼íŠ¸ më‹¹ ì„¤ì¹˜ìˆ˜", "më‹¹ ì„¤ì¹˜ìˆ˜"],
    }
    results_df = find_similar_keywords(df, keyword_dict)

    # ê²°ê³¼ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
    if not results_df.empty:
        # ê²°ê³¼ì— í˜ì´ì§€ ì •ë³´ ì¶”ê°€
        results_df['í˜ì´ì§€'] = page_idx

        for keyword in results_df['í‚¤ì›Œë“œ'].unique():
            keyword_df = results_df[results_df['í‚¤ì›Œë“œ'] == keyword]

            if keyword not in keyword_results:
                keyword_results[keyword] = keyword_df.copy()
            else:
                keyword_results[keyword] = pd.concat([keyword_results[keyword], keyword_df], ignore_index=True)

page_idx_m = keyword_results["më‹¹ í‰ê· ë‹¨ìœ„ìˆ˜ëŸ‰"]["í˜ì´ì§€"].values

keyword_dfs = []
# ìµœì¢… ê²°ê³¼ ì¶œë ¥ - ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
for keyword, df in keyword_results.items():
    # ìœ ì‚¬ë„ ì ìˆ˜ ì—´ì´ ìˆë‹¤ê³  ê°€ì •('ìœ ì‚¬ë„')
    if 'ìœ ì‚¬ë„' in df.columns:
        sorted_df = df.sort_values(by='ìœ ì‚¬ë„', ascending=False)  # ë†’ì€ ìœ ì‚¬ë„ë¶€í„° ì •ë ¬
    else:
        # ìœ ì‚¬ë„ ì—´ì´ ì—†ëŠ” ê²½ìš°, í˜ì´ì§€ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_df = df.sort_values(by='í˜ì´ì§€')
        st.write("(ìœ ì‚¬ë„ ì ìˆ˜ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ í˜ì´ì§€ ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤)")

    # í‚¤ì›Œë“œ ì •ë³´ ì¶”ê°€
    sorted_df['í‚¤ì›Œë“œ_ë¶„ë¥˜'] = keyword  # ì–´ë–¤ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ì¸ì§€ í‘œì‹œ
    keyword_dfs.append(sorted_df)
    # st.write(f"\n### í‚¤ì›Œë“œ: {keyword} ##")
    # st.write(f"ì´ {len(df)}ê°œì˜ í•­ëª© ë°œê²¬")
    # st.write(sorted_df)
    # st.write("---")

with tabs[0]:
    # ì´ì œ ëª¨ë“  í‚¤ì›Œë“œì— ëŒ€í•´ ê²°ê³¼ ì²˜ë¦¬
    keywords_to_process = list(keyword_results.keys())

    # ê° í‚¤ì›Œë“œë³„ë¡œ ì²˜ë¦¬
    for keyword in keywords_to_process:
        if keyword in keyword_results and not keyword_results[keyword].empty:
            # í•´ë‹¹ í‚¤ì›Œë“œì˜ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            sorted_df = (
                keyword_results[keyword].sort_values(by='ìœ ì‚¬ë„', ascending=False)
                if 'ìœ ì‚¬ë„' in keyword_results[keyword].columns
                else keyword_results[keyword]
            )

            # íŠ¹ì • í˜ì´ì§€ ë°ì´í„°ë§Œ ë‚¨ê¸°ê¸°
            if 'më‹¹' in keyword:
                sorted_df = sorted_df[sorted_df['í˜ì´ì§€'] == page_idx_m[0]]
            # ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            top_result = sorted_df.iloc[0]

            # í˜ì´ì§€ì™€ ì—´ ë²ˆí˜¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            page_idx = top_result['í˜ì´ì§€']
            col_idx = top_result['col_idx']  # if 'col_idx' in top_result.index else 1

            # í•´ë‹¹ í˜ì´ì§€ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if page_idx < len(cleaned_tables):
                v = cleaned_tables[page_idx]
                # 0ì—´(ì²« ë²ˆì§¸ ì—´)ì—ì„œ 0í–‰(êµ¬ë¶„) ë‹¤ìŒ ì²˜ìŒ ë°ì´í„°ê°€ ìˆëŠ” í–‰ ì°¾ê¸°
                first_valid_row = v.iloc[1:, 0][v.iloc[1:, 0].notna() & (v.iloc[1:, 0] != "")].index[0]
                # ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                if col_idx < v.shape[1]:
                    # í–‰ ì¸ë±ìŠ¤ 4ë¶€í„° ëê¹Œì§€ í•´ë‹¹ ì—´ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    column_data = v.iloc[first_valid_row:, col_idx]
                    # ìˆ«ìë¡œ ë³€í™˜ (ì²œë‹¨ìœ„ ì‰¼í‘œ ì œê±°, ë¬¸ìëŠ” ê·¸ëŒ€ë¡œ)
                    column_data = column_data.map(
                        lambda x: (
                            pd.to_numeric(x.replace(",", ""), errors="coerce")
                            if isinstance(x, str) and x.replace(",", "").replace(".", "").isdigit()
                            else x
                        )
                    )

                    # ê¸¸ì´ í™•ì¸ ë° ì¡°ì •
                    if len(column_data) > len(df_output):
                        column_data = column_data[: len(df_output)]
                    elif len(column_data) < len(df_output):
                        padding = [None] * (len(df_output) - len(column_data))
                        column_data = pd.concat([column_data, pd.Series(padding)])

                    # ê¸°ì¡´ ì—´ì´ ìˆìœ¼ë©´ ì‚­ì œ
                    if keyword in df_output.columns:
                        df_output = df_output.drop(columns=[keyword])

                    # ì—´ ì¶”ê°€ - 0ë²ˆ ìœ„ì¹˜ì— ì‚½ì…
                    df_output.insert(0, keyword, column_data.values)


def try_convert_to_float(x):
    try:
        return float(x)
    except (ValueError, TypeError):
        return x  # ë³€í™˜ ì‹¤íŒ¨ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜


for col in df_output.columns:
    df_output[col] = df_output[col].apply(try_convert_to_float)

# "ì‹œì " ì»¬ëŸ¼ í™•ì¸  # "ì¢…ì " ì»¬ëŸ¼ í™•ì¸
col_ì‹œì  = next((col for col in df_output.columns if "ì‹œì " in col), None)
col_ì¢…ì  = next((col for col in df_output.columns if "ì¢…ì " in col), None)
# "ì—°ì¥ ì†Œê³„" ê³„ì‚°
if col_ì‹œì  and col_ì¢…ì :
    df_output["ì—°ì¥ ì†Œê³„"] = df_output[col_ì‹œì ].fillna(0) + df_output[col_ì¢…ì ].fillna(0)
elif col_ì‹œì :
    df_output["ì—°ì¥ ì†Œê³„"] = df_output[col_ì‹œì ]


def sum_if_numeric(a, b):
    try:
        return float(a) + float(b)
    except (ValueError, TypeError):
        return math.nan


def multiply_if_numeric(a, b):
    try:
        return float(a) * float(b)
    except (ValueError, TypeError):
        return math.nan


df_output["êµ´ì°©ëŸ‰"] = [multiply_if_numeric(a, b) for a, b in zip(df_output["êµ´ì§„ì¥"], df_output["më‹¹ êµ´ì°©ëŸ‰"])]
df_output["ì—¬êµ´ëŸ‰"] = [multiply_if_numeric(a, b) for a, b in zip(df_output["êµ´ì§„ì¥"], df_output["më‹¹ ì—¬êµ´ëŸ‰"])]
df_output["ë²„ë ¥ ì²˜ë¦¬ëŸ‰"] = df_output["êµ´ì°©ëŸ‰"] + df_output["ì—¬êµ´ëŸ‰"]
df_output["ì´ êµ´ì°©ëŸ‰"] = [multiply_if_numeric(a, b) for a, b in zip(df_output["ì—°ì¥ ì†Œê³„"], df_output["më‹¹ êµ´ì°©ëŸ‰"])]
df_output["ì´ ë²„ë ¥ëŸ‰"] = [
    multiply_if_numeric(length, sum_if_numeric(m_gulchak, m_yeogul))
    for length, m_gulchak, m_yeogul in zip(df_output["ì—°ì¥ ì†Œê³„"], df_output["më‹¹ êµ´ì°©ëŸ‰"], df_output["më‹¹ ì—¬êµ´ëŸ‰"])
]

df_output["1ë°œíŒŒ íƒ€ì„¤"] = [multiply_if_numeric(a, b) for a, b in zip(df_output["êµ´ì§„ì¥"], df_output["më‹¹ ìˆí¬ë¦¬íŠ¸"])]
df_output["ì´ íƒ€ì„¤ëŸ‰"] = [multiply_if_numeric(a, b) for a, b in zip(df_output["ì—°ì¥ ì†Œê³„"], df_output["më‹¹ ìˆí¬ë¦¬íŠ¸"])]

# ë¬¸ì# 1) 'ì—°ì¥ ì†Œê³„'ë¥¼ ìˆ«ìë¡œ ë³€í™˜
df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] = pd.to_numeric(df_output["ì—°ì¥ ì†Œê³„"], errors="coerce")

# 2) ì¡°ê±´ë¬¸ ê²°í•©
df_output["ì²œê³µ ì¥ë¹„"] = np.where(
    df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"].notna() & (df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] > 0),
    # ìœ„ ì¡°ê±´(ìˆ«ì+ì–‘ìˆ˜) ì¶©ì¡±í•˜ë©´ np.selectë¡œ 'í„°ë„ ë‹¨ë©´êµ°' ê°’ì— ë”°ë¼ ë¶„ê¸°
    np.select([df_output["í„°ë„ ë‹¨ë©´êµ°"] == "C", df_output["í„°ë„ ë‹¨ë©´êµ°"] == "B"], [3, 2], default=0),
    # ì¡°ê±´ ë¶ˆë§Œì¡± ì‹œ -> ""
    "",
)
df_output["ì¥ë¹„ ê·œê²©"] = np.where(
    df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"].notna() & (df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] > 0),
    # ìœ„ ì¡°ê±´(ìˆ«ì+ì–‘ìˆ˜) ì¶©ì¡±í•˜ë©´ np.selectë¡œ 'í„°ë„ ë‹¨ë©´êµ°' ê°’ì— ë”°ë¼ ë¶„ê¸°
    np.select([df_output["í„°ë„ ë‹¨ë©´êµ°"] == "C", df_output["í„°ë„ ë‹¨ë©´êµ°"] == "B"], [3.5, 0.6], default=0.0),
    # ì¡°ê±´ ë¶ˆë§Œì¡± ì‹œ -> ""
    "",
)
df_output["ì²œê³µ ì†ë„"] = np.where(
    df_output["ì—°ì¥ ì†Œê³„"].astype(str).str.strip() == "",  # ë¹ˆ ë¬¸ìì—´ì´ë©´
    "",  # ê·¸ëŒ€ë¡œ ìœ ì§€
    np.where(df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] > 0, 1.0, 0.0),  # 0ë³´ë‹¤ í¬ë©´ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0
)
df_output["ì•”íŒŒì‡„"] = np.where(
    df_output["ì—°ì¥ ì†Œê³„"].astype(str).str.strip() == "",  # ë¹ˆ ë¬¸ìì—´ì´ë©´
    "",  # ê·¸ëŒ€ë¡œ ìœ ì§€
    np.where(df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] > 0, 3.4, 0.0),  # 0ë³´ë‹¤ í¬ë©´ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0
)

df_output["ì¥ë¹„ f"] = np.where(
    df_output["ì—°ì¥ ì†Œê³„"].astype(str).str.strip() == "",  # ë¹ˆ ë¬¸ìì—´ì´ë©´
    "",  # ê·¸ëŒ€ë¡œ ìœ ì§€
    np.where(df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] > 0, 0.615, 0.0),  # 0ë³´ë‹¤ í¬ë©´ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0
)
df_output["Q (ë¡œë”)"] = np.where(
    df_output["ì—°ì¥ ì†Œê³„"].astype(str).str.strip() == "",  # ë¹ˆ ë¬¸ìì—´ì´ë©´
    "",  # ê·¸ëŒ€ë¡œ ìœ ì§€
    np.where(df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] > 0, 82.667, 0.0),  # 0ë³´ë‹¤ í¬ë©´ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0
)
df_output["Q (ë°±í˜¸)"] = np.where(
    df_output["ì—°ì¥ ì†Œê³„"].astype(str).str.strip() == "",  # ë¹ˆ ë¬¸ìì—´ì´ë©´
    "",  # ê·¸ëŒ€ë¡œ ìœ ì§€
    np.where(df_output["ì—°ì¥ ì†Œê³„_ìˆ«ì"] > 0, 172.591, 0.0),  # 0ë³´ë‹¤ í¬ë©´ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0
)


# 3) ì„ì‹œ ë³€í™˜ ì»¬ëŸ¼ ì‚­ì œ
df_output.drop(columns=["ì—°ì¥ ì†Œê³„_ìˆ«ì"], inplace=True)
# st.write(df_output)

with tabs[0]:
    # df_output
    st.write("### :blue[<< pdfì—ì„œ ë°ì´í„° ì¶”ì¶œ >>]")
    create_st_aggrid(df_output, 'input')
    st.write("### :blue[<< ê³„ì‚° ë°ì´í„° >>]")
    create_st_aggrid(df_output, 'output')


with st.sidebar:
    st.write("---")
    st.write(f"í‘œ ê°œìˆ˜: {len(cleaned_tables)}")
    st.write(f"ì‹¤í–‰ ì‹œê°„: {time.time() - start_time:.2f} ì´ˆ")  # í¬ë§·íŒ… ì‚¬ìš©
